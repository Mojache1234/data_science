{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('Ariel': virtualenv)",
   "display_name": "Python 3.7.6 64-bit ('Ariel': virtualenv)",
   "metadata": {
    "interpreter": {
     "hash": "7bbc53da2d95dc41dd8ecbae1ddafb826ff85dd4e742267596895523cce3e7e5"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Voter File VANID LastName FirstName MiddleName Suffix  PreferredEmail  \\\n0          57812043     Peng   Jasmine        NaN    NaN             NaN   \n1          59291016   Flores     Akira        NaN    NaN             NaN   \n2          59700160    Brown    Thomas        NaN    NaN             NaN   \n3          57983287       Xu    Xuewei        NaN    NaN             NaN   \n4          59374587  Ansagay     Zhara   Michelle    NaN             NaN   \n\n  Party  Age  AL_Support   CountyName  ...      City State     Zip5    Zip4  \\\n0     U   21         NaN  Santa Clara  ...  San Jose    CA  95131.0  2755.0   \n1     D   19         NaN  Santa Clara  ...  San Jose    CA  95131.0  2778.0   \n2     U   19         NaN  Santa Clara  ...  San Jose    CA  95131.0  2780.0   \n3     U   39         NaN  Santa Clara  ...  San Jose    CA  95131.0  2784.0   \n4     D   18         NaN  Santa Clara  ...  San Jose    CA  95131.0  2735.0   \n\n   Cell Phone  CellPhoneIsCell Preferred Phone  PreferredPhoneIsCell  \\\n0         NaN              NaN    4.082723e+09     Likely Not a Cell   \n1         NaN              NaN             NaN                   NaN   \n2         NaN              NaN             NaN                   NaN   \n3         NaN              NaN             NaN                   NaN   \n4         NaN              NaN             NaN                   NaN   \n\n     Home Phone    HomePhoneIsCell  \n0  4.082723e+09  Likely Not a Cell  \n1           NaN                NaN  \n2           NaN                NaN  \n3           NaN                NaN  \n4           NaN                NaN  \n\n[5 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Voter File VANID</th>\n      <th>LastName</th>\n      <th>FirstName</th>\n      <th>MiddleName</th>\n      <th>Suffix</th>\n      <th>PreferredEmail</th>\n      <th>Party</th>\n      <th>Age</th>\n      <th>AL_Support</th>\n      <th>CountyName</th>\n      <th>...</th>\n      <th>City</th>\n      <th>State</th>\n      <th>Zip5</th>\n      <th>Zip4</th>\n      <th>Cell Phone</th>\n      <th>CellPhoneIsCell</th>\n      <th>Preferred Phone</th>\n      <th>PreferredPhoneIsCell</th>\n      <th>Home Phone</th>\n      <th>HomePhoneIsCell</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>57812043</td>\n      <td>Peng</td>\n      <td>Jasmine</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>U</td>\n      <td>21</td>\n      <td>NaN</td>\n      <td>Santa Clara</td>\n      <td>...</td>\n      <td>San Jose</td>\n      <td>CA</td>\n      <td>95131.0</td>\n      <td>2755.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.082723e+09</td>\n      <td>Likely Not a Cell</td>\n      <td>4.082723e+09</td>\n      <td>Likely Not a Cell</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>59291016</td>\n      <td>Flores</td>\n      <td>Akira</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>D</td>\n      <td>19</td>\n      <td>NaN</td>\n      <td>Santa Clara</td>\n      <td>...</td>\n      <td>San Jose</td>\n      <td>CA</td>\n      <td>95131.0</td>\n      <td>2778.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>59700160</td>\n      <td>Brown</td>\n      <td>Thomas</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>U</td>\n      <td>19</td>\n      <td>NaN</td>\n      <td>Santa Clara</td>\n      <td>...</td>\n      <td>San Jose</td>\n      <td>CA</td>\n      <td>95131.0</td>\n      <td>2780.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>57983287</td>\n      <td>Xu</td>\n      <td>Xuewei</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>U</td>\n      <td>39</td>\n      <td>NaN</td>\n      <td>Santa Clara</td>\n      <td>...</td>\n      <td>San Jose</td>\n      <td>CA</td>\n      <td>95131.0</td>\n      <td>2784.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>59374587</td>\n      <td>Ansagay</td>\n      <td>Zhara</td>\n      <td>Michelle</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>D</td>\n      <td>18</td>\n      <td>NaN</td>\n      <td>Santa Clara</td>\n      <td>...</td>\n      <td>San Jose</td>\n      <td>CA</td>\n      <td>95131.0</td>\n      <td>2735.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv('NEW_VOTERS.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Zip5'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FullAddress'] = df['Address'] + ' ' + df['City'] + ', ' + df['State'] + ' ' + df['Zip5'].astype(int).astype(str)\n",
    "df['FullName'] = df['FirstName'] + ' ' + df['LastName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df.groupby('Full_Address').LastName.agg(['unique', 'nunique'])\n",
    "df2 = df.groupby('FullAddress').agg({\n",
    "    'LastName': ['unique', 'nunique'],\n",
    "    'FullName': ['unique', 'nunique']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_multiple = df2.loc[df2['LastName']['nunique'] > 1].copy()\n",
    "df3_multiple['AddressedTo'] = [', '.join(x[:-1] + ' and ' + x[-1]) + ' Families' for x in df3_multiple['LastName']['unique']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_single_a = df2.loc[\n",
    "    (df2['LastName']['nunique'] == 1)\n",
    "     & (df2['FullName']['nunique'] == 1)\n",
    "].copy()\n",
    "df3_single_a['AddressedTo'] = [x[0] for x in df3_single_a['FullName']['unique']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_single_b = df2.loc[\n",
    "    (df2['LastName']['nunique'] == 1)\n",
    "     & (df2['FullName']['nunique'] > 1)\n",
    "].copy()\n",
    "df3_single_b['AddressedTo'] = [', '.join(x[:-1]) + ' and ' + x[-1] for x in df3_single_b['FullName']['unique']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([\n",
    "    df3_multiple['AddressedTo'],\n",
    "    df3_single_a['AddressedTo'],\n",
    "    df3_single_b['AddressedTo']\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "FullAddress\n100 Brook Ter Fremont, CA 94538                                    Lane and Laue Families\n1000 Poda Ct Fremont, CA 94539                                  Gomez and Greeff Families\n1001 E River Pkwy Santa Clara, CA 95054                          Vaccaro and Tow Families\n1001 S Main St Apt F203 Milpitas, CA 95035                       Lewis and Singh Families\n1001 S Main St Apt F312 Milpitas, CA 95035                      Khatun and Mukul Families\n                                                                 ...                     \n986 Sandalridge Ct Milpitas, CA 95035                       Ashok Sharma and Manju Sharma\n988 Madeline Ln Santa Clara, CA 95050                      Judith Ehrat and Stephen Ehrat\n990 Teal Dr Santa Clara, CA 95051                                   June Gan and Gary Gan\n991 Teal Dr Santa Clara, CA 95051                           Jerry Scott and Dolores Scott\n998 Garrity Way Santa Clara, CA 95054         Nicholas Desaulniers and Rachel Desaulniers\nName: AddressedTo, Length: 18225, dtype: object"
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "===========================================================================\n\n\n\n===== Importing + Cleaning NEW_VOTERS =====\n\n8596 unique addresses before dropna\n8594 unique addresses after dropna\n\n===== Staging Aggregation =====\n\nStaging Aggregation successful.\n\n===== Final Aggregation =====\n\n9 addresses with 3+ tenants\n---------------------------------------------------------------------------\n8 addresses with double family tenants\n---------------------------------------------------------------------------\n304 addresses with double individual tenants\n---------------------------------------------------------------------------\n5 addresses with single family (3+) tenants\n---------------------------------------------------------------------------\n228 addresses with single family (2) tenants\n---------------------------------------------------------------------------\n\n8040 addresses with single individual tenants\n---------------------------------------------------------------------------\n8594 addresses total after final aggregation\n---------------------------------------------------------------------------\n\nExporting NEW_VOTERS successful.\n\n===========================================================================\n\n\n\n===== Importing + Cleaning ONE_TIME_VOTERS =====\n\n29841 unique addresses before dropna\n29840 unique addresses after dropna\n\n===== Staging Aggregation =====\n\nStaging Aggregation successful.\n\n===== Final Aggregation =====\n\n217 addresses with 3+ tenants\n---------------------------------------------------------------------------\n391 addresses with double family tenants\n---------------------------------------------------------------------------\n2734 addresses with double individual tenants\n---------------------------------------------------------------------------\n355 addresses with single family (3+) tenants\n---------------------------------------------------------------------------\n2441 addresses with single family (2) tenants\n---------------------------------------------------------------------------\n\n23702 addresses with single individual tenants\n---------------------------------------------------------------------------\n29840 addresses total after final aggregation\n---------------------------------------------------------------------------\n\nExporting ONE_TIME_VOTERS successful.\n\n===========================================================================\n\n\n\n===== Importing + Cleaning HIGH_PROPENSITY_DEMOCRATS =====\n\n18225 unique addresses before dropna\n18225 unique addresses after dropna\n\n===== Staging Aggregation =====\n\nStaging Aggregation successful.\n\n===== Final Aggregation =====\n\n81 addresses with 3+ tenants\n---------------------------------------------------------------------------\n285 addresses with double family tenants\n---------------------------------------------------------------------------\n1605 addresses with double individual tenants\n---------------------------------------------------------------------------\n438 addresses with single family (3+) tenants\n---------------------------------------------------------------------------\n3350 addresses with single family (2) tenants\n---------------------------------------------------------------------------\n\n12466 addresses with single individual tenants\n---------------------------------------------------------------------------\n18225 addresses total after final aggregation\n---------------------------------------------------------------------------\n\nExporting HIGH_PROPENSITY_DEMOCRATS successful.\n\nDone.\n"
    }
   ],
   "source": [
    "csvs = ['NEW_VOTERS', 'ONE_TIME_VOTERS', 'HIGH_PROPENSITY_DEMOCRATS']\n",
    "\n",
    "for csv in csvs:\n",
    "    print('='*75+'\\n\\n')\n",
    "\n",
    "    # Import + Clean\n",
    "    print('\\n===== Importing + Cleaning ' + csv + ' =====\\n')\n",
    "    df = pd.read_csv(csv + '.csv')\n",
    "    print(df['Address'].nunique(), 'unique addresses before dropna')\n",
    "    df.dropna(how='any', subset=['Zip5', 'FirstName', 'LastName'], inplace=True)\n",
    "    print(df['Address'].nunique(), 'unique addresses after dropna')\n",
    "\n",
    "    # Create Columns\n",
    "    # df['FullAddress'] = df['Address'] + ' ' + df['City'] + ', ' + df['State'] + ' ' + df['Zip5'].astype(int).astype(str)\n",
    "    df['FullName'] = df['FirstName'] + ' ' + df['LastName']\n",
    "\n",
    "    # Staging Aggregation\n",
    "    print('\\n===== Staging Aggregation =====\\n')\n",
    "    # df2 = df.groupby('FullAddress').agg({\n",
    "    df2 = df.groupby(['Address', 'City', 'State', 'Zip5']).agg({\n",
    "        'FirstName': ['unique'],\n",
    "        'LastName': ['unique', 'nunique'],\n",
    "        'FullName': ['unique', 'nunique']\n",
    "    })\n",
    "    print('Staging Aggregation successful.')\n",
    "\n",
    "    # Final Aggregation\n",
    "    print('\\n===== Final Aggregation =====\\n')\n",
    "\n",
    "    # Find Houses w/ more than 9 tenants\n",
    "    # print('-'*75+'\\n')\n",
    "    # anomalies = df2.loc[df2['FullName']['nunique'] > 9]\n",
    "    # print(len(anomalies.index), 'addresses found with more than 9 tenants:')\n",
    "    # for i, a in zip(anomalies.index, anomalies):\n",
    "    #     print(i + '(' + str(anomalies['FullName']['nunique']) + '): ', anomalies['FullName']['unique'])\n",
    "    # print('-'*75+'\\n')\n",
    "\n",
    "    # Multiple Families (3+ families) -- \"Alex, Ariel, and Jason\"\n",
    "    df3_multiple = df2.loc[df2['LastName']['nunique'] > 2].copy()\n",
    "    print(len(df3_multiple.index), 'addresses with 3+ tenants')\n",
    "    df3_multiple['AddressedTo'] = [', '.join(x[:-1]) + ', and ' + x[-1] for x in df3_multiple['FirstName']['unique']]\n",
    "    df3_multiple['NumPersons'] = df3_multiple['FullName']['nunique']\n",
    "    print('-'*75)\n",
    "\n",
    "    # Double Families (2 families, 3+ people) -- \"Lee and Ongoco Families\"\n",
    "    df3_double_a = df2.loc[\n",
    "        (df2['LastName']['nunique'] == 2) &\n",
    "        (df2['FullName']['nunique'] > 2)\n",
    "    ].copy()\n",
    "    print(len(df3_double_a.index), 'addresses with double family tenants')\n",
    "    df3_double_a['AddressedTo'] = [' and '.join(x) + ' Families' for x in df3_double_a['LastName']['unique']]\n",
    "    df3_double_a['NumPersons'] = df3_double_a['FullName']['nunique']\n",
    "    print('-'*75)\n",
    "\n",
    "    # Double Persons (2 people) -- \"Alex Lee and Ariel Ongoco\"\n",
    "    df3_double_b = df2.loc[\n",
    "        (df2['LastName']['nunique'] == 2) &\n",
    "        (df2['FullName']['nunique'] == 2)\n",
    "    ].copy()\n",
    "    print(len(df3_double_b.index), 'addresses with double individual tenants')\n",
    "    df3_double_b['AddressedTo'] = [' and '.join(x) for x in df3_double_b['FullName']['unique']]\n",
    "    df3_double_b['NumPersons'] = df3_double_b['FullName']['nunique']\n",
    "    print('-'*75)\n",
    "    \n",
    "    # Single Families (1 family, 3+ persons) -- \"Lee Family\"\n",
    "    df3_single_b = df2.loc[\n",
    "        (df2['LastName']['nunique'] == 1)\n",
    "        & (df2['FullName']['nunique'] > 2)\n",
    "    ].copy()\n",
    "    print(len(df3_single_b.index), 'addresses with single family (3+) tenants')\n",
    "    df3_single_b['AddressedTo'] = [x[0] + ' Family' for x in df3_single_b['LastName']['unique']]\n",
    "    df3_single_b['NumPersons'] = df3_single_b['FullName']['nunique']\n",
    "    print('-'*75)\n",
    "\n",
    "    # Single Families (1 family, 2 persons) -- \"Alex and Darius Lee\"\n",
    "    df3_single_c = df2.loc[\n",
    "        (df2['LastName']['nunique'] == 1)\n",
    "        & (df2['FullName']['nunique'] == 2)\n",
    "    ].copy()\n",
    "    print(len(df3_single_c.index), 'addresses with single family (2) tenants')\n",
    "    df3_single_c['AddressedTo'] = [' and '.join(x) + ' ' + y for x, y[0] in zip(df3_single_c['FirstName']['unique'], df3_single_c['LastName']['unique'])]\n",
    "    df3_single_c['NumPersons'] = df3_single_c['FullName']['nunique']\n",
    "    print('-'*75+'\\n')\n",
    "\n",
    "    # Single Persons (1 person) -- \"Alex Lee\"\n",
    "    df3_single_a = df2.loc[df2['FullName']['nunique'] == 1].copy()\n",
    "    print(len(df3_single_a.index), 'addresses with single individual tenants')\n",
    "    df3_single_a['AddressedTo'] = [x[0] for x in df3_single_a['FullName']['unique']]\n",
    "    df3_single_a['NumPersons'] = df3_single_a['FullName']['nunique']\n",
    "    print('-'*75)\n",
    "\n",
    "    # Concatenate all df3's\n",
    "    df3 = pd.concat([\n",
    "        df3_multiple[['AddressedTo', 'NumPersons']],\n",
    "        df3_double_a[['AddressedTo', 'NumPersons']],\n",
    "        df3_double_b[['AddressedTo', 'NumPersons']],\n",
    "        df3_single_a[['AddressedTo', 'NumPersons']],\n",
    "        df3_single_b[['AddressedTo', 'NumPersons']],\n",
    "        df3_single_c[['AddressedTo', 'NumPersons']]\n",
    "    ])\n",
    "    print(len(df3.index), 'addresses total after final aggregation')\n",
    "    print('-'*75+'\\n')\n",
    "\n",
    "    # Export to new CSV\n",
    "    df3.to_csv(csv + '_DEDUPED.csv')\n",
    "    print('Exporting ' + csv + ' successful.\\n')\n",
    "\n",
    "print('Done.')"
   ]
  }
 ]
}